{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from typing import Dict\n",
    "from numbers import Real\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from hparam import Hparam\n",
    "from data_load import SpeakerDatasetPreprocessed\n",
    "from speech_embedder_net import SpeechEmbedder, SpeechEmbedder_Softmax, GE2ELoss_, AAMSoftmax,SubcenterArcMarginProduct, get_cossim\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import numpy as np\n",
    "import scipy.linalg\n",
    "import scipy.stats\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import seaborn as sns\n",
    "\n",
    "from utils import fit_bmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparatory Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all random seed to 1 to ensure consistent experiment output\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed_all(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hp.stage = 'nld', hp.nld.noise_type = 'Permute'\n",
      "hp.nld.model_path = '/home/yrb/code/speechbrain/data/models/Permute/GE2E/20%/m8_bs128/ckpt_epoch_200.pth'\n"
     ]
    }
   ],
   "source": [
    "# Load Hyperparameter configuration files\n",
    "hp = Hparam(file='config/config.yaml')\n",
    "model_path = hp.nld.model_path\n",
    "device = torch.device(hp.device)\n",
    "print(f'{hp.stage = }, {hp.nld.noise_type = }')\n",
    "print(f'{hp.nld.model_path = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_params(model):\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "\n",
    "    return params\n",
    "\n",
    "def extract_emb(embedder_net, batch):\n",
    "    if batch.ndim == 4:\n",
    "        batch = batch.reshape(-1, batch.size(2), batch.size(3))\n",
    "    if embedder_net.__class__.__name__ == 'SpeechEmbedder_Softmax':\n",
    "        embeddings = embedder_net.get_embedding(batch)\n",
    "    else:\n",
    "        embeddings = embedder_net(batch)\n",
    "    return embeddings\n",
    "\n",
    "# TODO finish all function docstrings\n",
    "def get_hyperparameters_from_path(model_absolute_path: str) -> Dict[str, Real]:\n",
    "    directory_name = os.path.dirname(model_absolute_path)\n",
    "    last_folder_name = directory_name.split('/')[-1]\n",
    "    ret: Dict[str, Real] = dict()\n",
    "    for param in last_folder_name.split('_'):\n",
    "        for i, char in enumerate(param):\n",
    "            if not char.isalpha():\n",
    "                key = param[:i]\n",
    "                value = float(param[i:])\n",
    "                if value.is_integer():\n",
    "                    value = int(value)\n",
    "                ret[key] = value\n",
    "                break\n",
    "    return ret\n",
    "\n",
    "\n",
    "def get_loss_type(model_absolute_path: str):\n",
    "    for i in ['/Softmax/', '/GE2E/', '/AAM/', '/AAMSC/']:\n",
    "        if i in model_absolute_path:\n",
    "            if i == '/Softmax/':\n",
    "                return 'Softmax'\n",
    "            elif i == '/GE2E/':\n",
    "                return 'GE2E'\n",
    "            elif i == '/AAM/':\n",
    "                return 'AAM'\n",
    "            else:\n",
    "                return 'AAMSC'\n",
    "    return NotImplemented\n",
    "\n",
    "\n",
    "def get_criterion(device, model_path):\n",
    "    loss_type = get_loss_type(model_path)\n",
    "    # TODO read hyperparameter from `get_hyperparameters_from_path`\n",
    "    if loss_type == 'Softmax':\n",
    "        criterion = torch.nn.NLLLoss()\n",
    "    elif loss_type == 'GE2E':\n",
    "        criterion = GE2ELoss_(init_w=10.0, init_b=-5.0, loss_method='softmax').to(device)\n",
    "    elif loss_type == 'AAM':\n",
    "        criterion = AAMSoftmax(hp.model.proj, 5994, scale=hp.train.s, margin=hp.train.m, easy_margin=True).to(device)\n",
    "    elif loss_type == 'AAMSC':\n",
    "        criterion = SubcenterArcMarginProduct(hp.model.proj, 5994, s=hp.train.s, m=hp.train.m, K=hp.train.K).to(device)\n",
    "    else:\n",
    "        raise ValueError('Unknown loss')\n",
    "    return criterion, loss_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised GE2E\n",
      "Number of params: 12134656\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    embedder_net = SpeechEmbedder(hp).to(device)\n",
    "    embedder_net.load_state_dict(torch.load(model_path))\n",
    "except:\n",
    "    embedder_net = SpeechEmbedder_Softmax(hp=hp, num_classes=5994).to(device)\n",
    "    embedder_net.load_state_dict(torch.load(model_path))\n",
    "\n",
    "criterion = get_criterion(hp.device, model_path)[0]\n",
    "criterion.load_state_dict(torch.load(model_path.replace('ckpt_epoch', 'ckpt_criterion_epoch')))\n",
    "embedder_net.eval()\n",
    "criterion.eval()\n",
    "\n",
    "print(f\"Number of params: {get_n_params(embedder_net)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\mathbf{c}_{s}=\\frac{1}{\\sum_{u} 1} \\sum_{u} \\mathbf{f}_{s, u}$\n",
    "## $\\mathbf{d(f_{s, u}, c_s)} = 1 - \\dfrac{\\mathbf{f}_{s, u} \\cdot \\mathbf{c}_s}{\\Vert \\mathbf{f}_{s, u} \\Vert _2 \\cdot \\Vert \\mathbf{c}_s \\Vert _2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypreds = []\n",
    "ylabels = []\n",
    "\n",
    "\n",
    "cos = torch.nn.CosineSimilarity(dim=-1, eps=1e-6)\n",
    "nld_dataset = SpeakerDatasetPreprocessed(hp)\n",
    "nld_loader = DataLoader(nld_dataset, batch_size=hp.nld.N, shuffle=False, num_workers=hp.nld.num_workers, drop_last=False)\n",
    "for batch_id, (mel_db_batch, labels, is_noisy, utterance_ids) in enumerate(tqdm(nld_loader)):\n",
    "    utterance_ids = np.array(utterance_ids).T\n",
    "    mel_db_batch = mel_db_batch.to(device)\n",
    "    \n",
    "    embeddings = extract_emb(embedder_net, mel_db_batch) \n",
    "    embeddings = torch.reshape(embeddings, (hp.nld.N, hp.nld.M, embeddings.size(1))) # (1, M, 256)\n",
    "    centroid = embeddings.mean(dim=1, keepdim=True)\n",
    "    embeddings = embeddings / embeddings.norm(dim=2, keepdim=True) \n",
    "    centroid = centroid / centroid.norm(dim=2, keepdim=True)\n",
    "    cos_sim = get_cossim(embeddings, centroid, cos)\n",
    "    ypreds.extend((1 - cos_sim).reshape(-1).cpu().detach().numpy().tolist())\n",
    "    ylabels.extend(is_noisy.reshape(-1).cpu().detach().numpy().tolist())\n",
    "    if batch_id == 500:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select top noise level % from ypreds\n",
    "noise_level = hp.nld.noise_level\n",
    "print(\"noise level: \", hp.nld.noise_level)\n",
    "ypreds = np.array(ypreds)\n",
    "ylabels = np.array(ylabels)\n",
    "\n",
    "def compute_precision(ypreds, ylabels, noise_level):\n",
    "    selected = np.argsort(ypreds)[-int(len(ypreds) * noise_level / 100):]\n",
    "    selected_ypreds = ypreds[selected]\n",
    "    selected_ylabels = ylabels[selected]\n",
    "    # compute precision\n",
    "    return selected_ylabels.sum() / len(selected_ylabels)\n",
    "\n",
    "print(\"top noise level precision: \", compute_precision(ypreds, ylabels, noise_level))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df from ypreds and ylabels\n",
    "df = pd.DataFrame({\"Distance\": ypreds, \"isNoisy\": ylabels})\n",
    "print(\"plot distance distribution\")\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "# ax = sns.displot(ypreds)\n",
    "p = sns.displot(df, x=\"Distance\", hue=\"isNoisy\")\n",
    "p.fig.set_dpi(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict with BMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmm_model, bmm_model_max, bmm_model_min = fit_bmm(ypreds, max_iters=50)\n",
    "bmm_model.plot()\n",
    "\n",
    "# Noise level estimation\n",
    "if hp.nld.noise_level >=70:\n",
    "    estimated_noise_level = bmm_model.weight[0]\n",
    "else:\n",
    "    estimated_noise_level = bmm_model.weight[1]\n",
    "print(\"Estimated noise level: \", estimated_noise_level)\n",
    "print(\"Noise level: \", ylabels.sum() / len(ylabels) * 100)\n",
    "print(\"top estimated noise level precision: \", compute_precision(ypreds, ylabels, estimated_noise_level))\n",
    "print(\"top noise level precision: \", compute_precision(ypreds, ylabels, hp.nld.noise_level))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypreds_bmm = bmm_model.predict(ypreds)\n",
    "if hp.nld.noise_level >=70:\n",
    "    ypreds_bmm = 1 - ypreds_bmm\n",
    "bmm_precision = (ypreds_bmm * ylabels).sum() / ypreds_bmm.sum()\n",
    "print(\"BMM precision: \", bmm_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict with GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_model = GaussianMixture(n_components=2, random_state=1)\n",
    "gmm_model.fit(ypreds.reshape(-1, 1))\n",
    "\n",
    "\n",
    "# Noise level estimation\n",
    "ypreds_gmm = gmm_model.predict(ypreds.reshape(-1, 1))\n",
    "if gmm_model.means_[0][0] > gmm_model.means_[1][0]:\n",
    "    ypreds_gmm = 1 - ypreds_gmm\n",
    "estimated_noise_level = ypreds_gmm.sum() / len(ypreds) * 100\n",
    "print(\"Estimated noise level: \", estimated_noise_level)\n",
    "print(\"Noise level: \", ylabels.sum() / len(ylabels) * 100)\n",
    "print(\"top estimated noise level precision: \", compute_precision(ypreds, ylabels, estimated_noise_level))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_precision = (ypreds_gmm * ylabels).sum() / ypreds_gmm.sum()\n",
    "print(\"GMM precision: \", gmm_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathbf{I}_c = \\max((1 - \\mathbf{y}) * \\text{\\textbf{CLS}}(\\mathbf{x}; \\theta))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading spkr2utter and spkr2utter_mislabel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2918286/2918286 [00:08<00:00, 333395.30it/s]\n"
     ]
    }
   ],
   "source": [
    "cos = torch.nn.CosineSimilarity(dim=-1, eps=1e-6)\n",
    "nld_dataset = SpeakerDatasetPreprocessed(hp)\n",
    "nld_loader = DataLoader(nld_dataset, batch_size=hp.nld.N, shuffle=False, num_workers=0, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the confidence ranking with CE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_c_collection_ce = np.array([])\n",
    "is_noisy_collection_ce = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_id, (mel_db_batch, labels, is_noisy, utterance_ids) in enumerate(tqdm(nld_loader)):\n",
    "    # utterance_ids = np.array(utterance_ids).T\n",
    "\n",
    "    y = F.one_hot(labels.flatten(), len(nld_dataset)).to(device) # tensor size: (M, 5994)\n",
    "\n",
    "    mel_db_batch = mel_db_batch.to(device)\n",
    "    if mel_db_batch.ndim == 4:\n",
    "        mel_db_batch = mel_db_batch.reshape(-1, mel_db_batch.size(2), mel_db_batch.size(3))\n",
    "\n",
    "    embeddings = embedder_net.get_embedding(mel_db_batch)\n",
    "    # embeddings = torch.reshape(embeddings, (hp.nld.N, hp.nld.M, embeddings.size(1))) # (1, M, 256)\n",
    "\n",
    "    confidence = embedder_net.get_confidence(embeddings)\n",
    "\n",
    "    i_c = ((1 - y) * confidence).max(dim=1)\n",
    "\n",
    "    # is_noisy_flatten = is_noisy.flatten()\n",
    "    # i_c_not_noisy = i_c[is_noisy_flatten == 0]\n",
    "    # i_c_noisy = i_c[is_noisy_flatten == 1]\n",
    "\n",
    "    i_c_collection_ce = np.hstack([i_c_collection_ce, i_c.values.cpu().detach().numpy()])\n",
    "    is_noisy_collection_ce = np.hstack([is_noisy_collection_ce, is_noisy.flatten().cpu().detach().numpy()])\n",
    "\n",
    "    if batch_id == 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_c_noisy_ce = i_c_collection_ce[is_noisy_collection_ce == 1]\n",
    "i_c_not_noisy_ce = i_c_collection_ce[is_noisy_collection_ce == 0]\n",
    "print(f'{i_c_noisy_ce.mean() = }, {i_c_noisy_ce.var() = }')\n",
    "print(f'{i_c_not_noisy_ce.mean() = }, {i_c_not_noisy_ce.var() = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the confidence ranking using GE2E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_c_collection_ge2e = np.array([])\n",
    "is_noisy_collection_ge2e = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1499 [32:59<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5952/2191174172.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mconfidence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_confidence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mi_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mconfidence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mi_c_collection_ge2e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_c_collection_ge2e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "for batch_id, (mel_db_batch, labels, is_noisy, utterance_ids) in enumerate(tqdm(nld_loader)):\n",
    "    y = F.one_hot(labels.flatten(), len(nld_dataset)).to(device) # tensor size: (M, 5994)\n",
    "\n",
    "    mel_db_batch = mel_db_batch.to(device)\n",
    "    if mel_db_batch.ndim == 4:\n",
    "        mel_db_batch = mel_db_batch.reshape(-1, mel_db_batch.size(2), mel_db_batch.size(3))\n",
    "\n",
    "    ge2e_centroid = mel_db_batch.mean(dim=1)\n",
    "\n",
    "    embeddings = embedder_net.get_embedding(mel_db_batch)\n",
    "    embeddings = embeddings.reshape((hp.nld.N, hp.nld.M, embeddings.size(1)))\n",
    "    confidence = criterion.get_confidence(embeddings)\n",
    "\n",
    "    i_c = ((1 - y) * confidence).max(dim=1)\n",
    "\n",
    "    i_c_collection_ge2e = np.hstack([i_c_collection_ge2e, i_c.values.cpu().detach().numpy()])\n",
    "    is_noisy_collection_ge2e = np.hstack([is_noisy_collection_ge2e, is_noisy.flatten().cpu().detach().numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_c_noisy_ge2e = i_c_collection_ge2e[is_noisy_collection_ge2e == 1]\n",
    "i_c_not_noisy_ge2e = i_c_collection_ge2e[is_noisy_collection_ge2e == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot PR curve and ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(\"P-R Curve\")\n",
    "plt.title('Precision/Recall Curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "precision, recall, thresholds = precision_recall_curve(ylabels, ypreds)\n",
    "plt.plot(recall,precision)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot roc curve and compute auc\n",
    "fpr, tpr, thresholds = roc_curve(ylabels, ypreds)\n",
    "auc = scipy.integrate.trapz(tpr, fpr)\n",
    "plt.figure(\"ROC Curve\")\n",
    "plt.title('ROC Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.show()\n",
    "print(\"AUC: \", auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('speechbrain_ENV')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "39e9aee69d185e1dd34836a7e25e7f7b289042cc78d69e6ead41714ab0f9ce95"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
