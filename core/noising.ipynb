{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import torchaudio\n",
    "\n",
    "def print_metadata(metadata, src=None):\n",
    "  if src:\n",
    "    print(\"-\" * 10)\n",
    "    print(\"Source:\", src)\n",
    "    print(\"-\" * 10)\n",
    "  print(\" - sample_rate:\", metadata.sample_rate)\n",
    "  print(\" - num_channels:\", metadata.num_channels)\n",
    "  print(\" - num_frames:\", metadata.num_frames)\n",
    "  print(\" - bits_per_sample:\", metadata.bits_per_sample)\n",
    "  print(\" - encoding:\", metadata.encoding)\n",
    "  print()\n",
    "\n",
    "def inspect_file(path):\n",
    "    print(\"-\" * 10)\n",
    "    print(\"Source:\", path)\n",
    "    print(\"-\" * 10)\n",
    "    print(f\" - File size: {os.path.getsize(path)} bytes\")\n",
    "    print_metadata(torchaudio.info(path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Source: /home/yrb/code/speechbrain/data/ESC-50/audio/1-137-A-32.wav\n",
      "----------\n",
      " - File size: 160044 bytes\n",
      " - sample_rate: 16000\n",
      " - num_channels: 1\n",
      " - num_frames: 80000\n",
      " - bits_per_sample: 16\n",
      " - encoding: PCM_S\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inspect_file(\"/home/yrb/code/speechbrain/data/ESC-50/audio/1-137-A-32.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Source: /home/yrb/code/speechbrain/data/voxceleb/vox1/wav/id10001/1zcIwhmdeo4/00001.wav\n",
      "----------\n",
      " - File size: 259886 bytes\n",
      " - sample_rate: 16000\n",
      " - num_channels: 1\n",
      " - num_frames: 129921\n",
      " - bits_per_sample: 16\n",
      " - encoding: PCM_S\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inspect_file(\"/home/yrb/code/speechbrain/data/voxceleb/vox1/wav/id10001/1zcIwhmdeo4/00001.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# audio normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing db...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:04<00:00, 450.20it/s]\n"
     ]
    }
   ],
   "source": [
    "import pydub\n",
    "import os\n",
    "\n",
    "\n",
    "def normalize_audio(path, save_path):\n",
    "    \"\"\"\n",
    "    Normalize audio file.\n",
    "    \"\"\"\n",
    "    audio = pydub.AudioSegment.from_wav(path)\n",
    "    audio = audio.set_sample_width(2).set_channels(1).set_frame_rate(16000)\n",
    "    normalized_audio = audio.normalize()\n",
    "    normalized_audio.export(save_path, format=\"wav\")\n",
    "\n",
    "def find_all_files_with_extension(path, extension):\n",
    "    \"\"\"\n",
    "    Walk and find all files with a given extension in a directory.\n",
    "    \"\"\"\n",
    "    files = []\n",
    "    for root, dirnames, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith(extension):\n",
    "                files.append(os.path.join(root, filename))\n",
    "    return files\n",
    "\n",
    "def normalize_all_audio(path):\n",
    "    \"\"\"\n",
    "    Normalize all audio files in a directory.\n",
    "    \"\"\"\n",
    "    files = find_all_files_with_extension(path, \".wav\")\n",
    "    for f in tqdm(files):\n",
    "        normalize_audio(f, f)\n",
    "\n",
    "print(\"Normalizing db...\")\n",
    "db_path = \"/home/yrb/code/speechbrain/data/ESC-50/audio\"\n",
    "normalize_all_audio(db_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breakdown large speakerID.npy into one utter per .npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "def break_into_single_npy(db, db_single):\n",
    "    npy_list = os.listdir(db)\n",
    "    spkrID_list = [f[:-4] for f in npy_list if f.endswith(\".npy\")]\n",
    "    files = [os.path.join(db, f) for f in npy_list if f.endswith(\".npy\")]\n",
    "    for spkr_i, utter_p in enumerate(tqdm(files)):\n",
    "        data = np.load(utter_p)\n",
    "        for utter_i in range(data.shape[0]):\n",
    "            # get random float between 0 and 1\n",
    "            cur_utter = data[utter_i, :, :].reshape(1, data.shape[1], data.shape[2])\n",
    "            # save utter to db_single\n",
    "            np.save(os.path.join(db_single, spkrID_list[spkr_i] + \"_\" + str(utter_i) + \".npy\"), cur_utter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 4150.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# db = \"/home/yrb/code/speechbrain/data/voxceleb/vox1_test/spmel\"\n",
    "# db_single = \"/home/yrb/code/speechbrain/data/voxceleb/vox1_test/spmel_single\"\n",
    "\n",
    "# break_into_single_npy(db, db_single)\n",
    "\n",
    "# db = \"/home/yrb/code/speechbrain/data/voxceleb/vox1/spmel\"\n",
    "# db_single = \"/home/yrb/code/speechbrain/data/voxceleb/vox1/spmel_single\"\n",
    "\n",
    "# break_into_single_npy(db, db_single)\n",
    "\n",
    "# db = \"/home/yrb/code/speechbrain/data/voxceleb/vox2/spmel\"\n",
    "# db_single = \"/home/yrb/code/speechbrain/data/voxceleb/vox2/spmel_single\"\n",
    "\n",
    "# break_into_single_npy(db, db_single)\n",
    "\n",
    "db = \"/home/yrb/code/speechbrain/data/ESC-50/spmel\"\n",
    "db_single = \"/home/yrb/code/speechbrain/data/ESC-50/spmel_single\"\n",
    "\n",
    "break_into_single_npy(db, db_single)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Speaker list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "vox2_db = \"/home/yrb/code/speechbrain/data/voxceleb/vox2/spmel\"\n",
    "vox1_db = \"/home/yrb/code/speechbrain/data/voxceleb/vox1/spmel\"\n",
    "vox1test_db = \"/home/yrb/code/speechbrain/data/voxceleb/vox1_test/spmel\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "def get_speaker_list(db):\n",
    "    files = os.listdir(db)\n",
    "    files.sort()\n",
    "    spkrID_list = [f[:-4] for f in files if f.endswith(\".npy\")]\n",
    "    spkr2id = {}\n",
    "    for i, spkr in enumerate(spkrID_list):\n",
    "        spkr2id[spkr] = i\n",
    "    return spkr2id\n",
    "\n",
    "def save_as_json(db, json_path):\n",
    "    spkr2id = get_speaker_list(db)\n",
    "    with open(json_path, \"w\") as f:\n",
    "        json.dump(spkr2id, f)\n",
    "\n",
    "save_as_json(vox2_db, os.path.join(vox2_db, \"../spkr2id.json\"))\n",
    "save_as_json(vox1_db, os.path.join(vox1_db, \"../spkr2id.json\"))\n",
    "save_as_json(vox1test_db, os.path.join(vox1test_db, \"../spkr2id.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "vox1_db = \"/home/yrb/code/speechbrain/data/voxceleb/vox1/spmel_single\"\n",
    "vox2_db = \"/home/yrb/code/speechbrain/data/voxceleb/vox2/spmel_single\"\n",
    "noise_level = 75\n",
    "random.seed(noise_level)\n",
    "np.random.seed(noise_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2918286/2918286 [00:01<00:00, 2085779.61it/s]\n"
     ]
    }
   ],
   "source": [
    "npy_list = os.listdir(vox2_db)\n",
    "spkrID_list = list(json.load(open(os.path.join(vox2_db, \"../spkr2id.json\"), \"r\")).keys())\n",
    "\n",
    "npy_list.sort()\n",
    "spkrID_list.sort()\n",
    "\n",
    "mislabel_dict = {}\n",
    "for f in tqdm(npy_list):\n",
    "    # get random float between 0 and 1\n",
    "    if random.random() <= noise_level/100:\n",
    "        key = f[:-4]\n",
    "        # sample a random speaker\n",
    "        mislabel_dict[key] = random.sample(spkrID_list, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to json\n",
    "with open(f\"/home/yrb/code/speechbrain/data/jsons/Permute/voxceleb2_{noise_level}%_mislabel.json\", \"w\") as f:\n",
    "    json.dump(mislabel_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2918286/2918286 [00:03<00:00, 772566.28it/s]\n"
     ]
    }
   ],
   "source": [
    "npy_list = os.listdir(vox2_db)\n",
    "spkrID_list = list(json.load(open(os.path.join(vox2_db, \"../spkr2id.json\"), \"r\")).keys())\n",
    "ood_list = os.listdir(vox1_db)\n",
    "\n",
    "npy_list.sort()\n",
    "spkrID_list.sort()\n",
    "ood_list.sort()\n",
    "\n",
    "mislabel_dict = {}\n",
    "for f in tqdm(npy_list):\n",
    "    # get random float between 0 and 1\n",
    "    if random.random() <= noise_level/100:\n",
    "        key = f[:-4]\n",
    "        # sample a random file\n",
    "        mislabel_dict[key] = random.sample(ood_list, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to json\n",
    "with open(f\"/home/yrb/code/speechbrain/data/jsons/Open/voxceleb2_{noise_level}%_mislabel.json\", \"w\") as f:\n",
    "    json.dump(mislabel_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2918286/2918286 [00:03<00:00, 772987.97it/s]\n"
     ]
    }
   ],
   "source": [
    "npy_list = os.listdir(vox2_db)\n",
    "spkrID_list = list(json.load(open(os.path.join(vox2_db, \"../spkr2id.json\"), \"r\")).keys())\n",
    "ood_list = os.listdir(vox1_db)\n",
    "\n",
    "npy_list.sort()\n",
    "spkrID_list.sort()\n",
    "ood_list.sort()\n",
    "\n",
    "mislabel_dict = {}\n",
    "for f in tqdm(npy_list):\n",
    "    # get random float between 0 and 1\n",
    "    if random.random() <= noise_level/100:\n",
    "        key = f[:-4]\n",
    "        if random.random() <= 0.5:\n",
    "            # sample a random speaker\n",
    "            mislabel_dict[key] = random.sample(spkrID_list, 1)[0]\n",
    "        else:\n",
    "            # sample a random file\n",
    "            mislabel_dict[key] = random.sample(ood_list, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to json\n",
    "with open(f\"/home/yrb/code/speechbrain/data/jsons/Mix/voxceleb2_{noise_level}%_mislabel.json\", \"w\") as f:\n",
    "    json.dump(mislabel_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a15651361ac08648cc0367cb81428254d02008058b337497661685a8a3614813"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('speechbrain_ENV')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
